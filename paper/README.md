# 5 D√≠as Construyendo un Sistema OCR Distribuido: Event Driven Architecture en la Pr√°ctica

**Luis Correa**  
üíª Computer Scientist | Solution Architect | Software Engineer

---

Llevaba meses hablando de Event Driven Architecture y Microservicios. Dando opiniones. Criticando implementaciones ajenas. Pero como decimos en la industria "Hablar es barato, show me the code."

He construido sistemas "Semi EDA" para algunas empresas, proyectos h√≠bridos con arquitecturas mixtas. Pero todo en repositorios privados, invisible para el resto del mundo.

Decid√≠ que era hora de cambiar eso. Construir algo p√∫blico, funcional, que no se quedara en teor√≠a ni en slides de PowerPoint. Un proyecto "de juguete" lo suficientemente serio como para demostrar patrones reales.

As√≠ que me propuse un reto: construir un sistema de OCR distribuido. Subes un PDF, el sistema lo procesa en paralelo y te devuelve el texto extra√≠do. Nada revolucionario. Pero hacerlo _bien_ -escalable, resiliente, observable- result√≥ ser un viaje fascinante por todo lo que est√° mal (y bien) con los sistemas distribuidos modernos.

El resultado es [EDA Workshop](https://github.com/luiscib3r/eda-workshop): 5 microservicios (yo les llamo nanoservicios), NATS JetStream, Postgres, Kubernetes, y suficiente complejidad operativa como para cuestionar todas mis decisiones de vida.

Este no es un tutorial paso a paso. Es la historia honesta de c√≥mo lo constru√≠, las decisiones que tom√©, las que me arrepiento, y las herramientas que salvaron mi cordura.

---

## Episodio 0: El Infierno del "Localhost"

Antes de escribir una l√≠nea de l√≥gica de negocio, me top√© con el verdadero enemigo de los microservicios: **el entorno de desarrollo local**.

¬øC√≥mo ejecutas 5 servicios de Go, Postgres, NATS, S3, y mantienes tu laptop sin explotar? Si tu respuesta es "10 pesta√±as de terminal con `go run`", d√©jame ahorrarte tiempo: no funciona. No a largo plazo.

### La Soluci√≥n: Tilt

Termin√© usando [Tilt](https://tilt.dev/). No es sexy. No tiene una p√°gina de marketing con gradientes violetas y promesas de "10x developer productivity". Es solo una herramienta que _funciona_.

Tilt observa tu c√≥digo, reconstruye solo lo que cambi√≥, y actualiza los contenedores en Kubernetes local (uso k3d) en segundos. Los logs de todos los servicios en una ventana. Las dependencias bien definidas (no levantes el backend hasta que Postgres est√© listo).

![Tilt](images/tilt.png)

```python
# Fragmento del Tiltfile
# ===========================================================
# OCR Image Service
# ===========================================================
docker_build(
    'ocr-image',
    context='./backend',
    dockerfile='k8s.local/Dockerfile.ocr',
)

k8s_yaml('k8s.local/ocr-image/deployment.yaml')
k8s_resource(
    'ocr-image',
    labels='backend',
    resource_deps=['ocr'],
    trigger_mode=TRIGGER_MODE_MANUAL,
)
```

**La parte honesta:** Tilt tiene una curva de aprendizaje. Kubernetes local puede ser pesado. Pero una vez configurado, el "inner loop" (c√≥digo ‚Üí build ‚Üí test) es _incre√≠blemente_ r√°pido. Cambio una funci√≥n en Go, Tilt la recompila, actualiza el pod, y veo el resultado en menos de 5 segundos.

¬øVale la pena? Si vas a tener m√°s de 3 servicios, absolutamente.

---

## Episodio 1: El Broker que No Quer√≠a Usar (NATS JetStream)

Necesitaba un message broker. Mi primera opci√≥n fue Kafka porque "es lo que usan las empresas grandes".

Luego record√© que Kafka requiere ZooKeeper (o KRaft), consume RAM como si estuviera en oferta, y tiene una curva de aprendizaje m√°s empinada que aprender Haskell. Para este proyecto de OCR, era como usar un bulldozer para plantar una flor.

As√≠ que eleg√≠ **NATS JetStream** por razones pragm√°ticas:

1. **Es un binario √∫nico** de ~30MB. No necesita Java, no necesita ZooKeeper, no necesita sacrificios a los dioses de la JVM.
2. **JetStream agrega persistencia** al core de NATS. Los mensajes sobreviven reinicios, los consumers pueden hacer replay, y tiene delivery guarantees decentes.
3. Cre√© algunas capas de abstracci√≥n para facilitarme la vida.

```go
// Publicar un evento
event := events.NewFileUploadedEvent(&storage.FileUploadedEventData{
    FileName: req.FileName,
    FileKey:  req.FileKey,
})
producer.Publish(ctx, event)
```

![event-flow](images/event-flow.png)

### La Abstracci√≥n que Salv√≥ mi Sanidad

Para no repetir c√≥digo de suscripci√≥n en cada servicio, cre√© un `NatsConsumer[T]` gen√©rico en Go. Define tu handler, pasa el tipo de evento, y el consumer maneja todo el resto (ACKs, retries, graceful shutdown).

```go
consumer.NatsConsumer = nats.NewNatsConsumer(
		name,
		events.OCR_CHANNEL,
		events.FILE_PAGE_REGISTERED_EVENT,
		numWorkers,
		workerBufferSize,
		events.NewFilePageRegisteredEventFromMessage,
		consumer.handler,
		js,
		jetstream.ConsumerConfig{
			Name:          name,
			Durable:       name,
			Description:   "OCR File Page Registered Event Consumer",
			FilterSubject: events.FILE_PAGE_REGISTERED_EVENT,
			DeliverPolicy: jetstream.DeliverNewPolicy,
		},
)
consumer.Subscribe(ctx)
```

**La parte honesta:** NATS es genial para casos de uso como este. Pero si necesitas _exact-once delivery_ o particionamiento complejo como Kafka, est√°s frito. JetStream tiene _at-least-once_, lo que significa que tu c√≥digo debe ser idempotente. Si no sabes qu√© significa eso, aprende antes de usar _cualquier_ message broker.

---

## Episodio 2: El Contrato Sagrado (Protobuf o el Caos)

En sistemas distribuidos, JSON es el equivalente a programar sin tests: funciona hasta que no funciona.

Un servicio env√≠a `user_id`, otro espera `userId`. Boom. Runtime error en producci√≥n.

Decid√≠ que **todo** se comunica con Protocol Buffers. No negociable.

### Buf: Protoc con Esteroides

Usar `protoc` directamente es como cocinar con utensilios oxidados. Funciona, pero sufres. [Buf](https://buf.build/) es la versi√≥n moderna:

1. **Linting estricto:** Si rompo compatibilidad backward, Buf me grita antes del commit.
2. **Generaci√≥n unificada:** Un solo comando genera c√≥digo Go, TypeScript para el frontend, y documentaci√≥n OpenAPI.
3. **Registro remoto:** Puedes publicar tus schemas y compartirlos entre equipos.

```protobuf
// events.proto
message FilePageOcrGeneratedEventData {
  string id = 1;
  string file_id = 2;
  int32 page_number = 3;
  string page_image_key = 4;
}
```

![proto-events](images/proto-events.png)

Ejecuto `buf generate` y obtengo:

- Structs de Go con validaci√≥n
- Swagger docs

**La parte honesta:** Protobuf agrega fricci√≥n inicial. Tienes que aprender la sintaxis, configurar Buf, y convencer a tu equipo de que "no, JSON no es suficiente". Pero el d√≠a que despliegas un cambio breaking y _el compilador te avisa antes de que llegue a producci√≥n_, entiendes por qu√© existe.

---

## Episodio 3: Fan-Out (o C√≥mo un Evento Dispara M√∫ltiples Cosas)

Aqu√≠ es donde EDA empieza a brillar de verdad.

Cuando un usuario sube un archivo, publico un `FileUploadedEvent`. ¬øQui√©n lo consume?

1. **Storage Consumer:** Guarda metadata en Postgres.
2. **OCR Image Service:** Descarga el PDF y lo convierte en im√°genes.
3. **Audit Service** (futuro): Registra qui√©n subi√≥ qu√©.

Ninguno de estos servicios sabe de la existencia del otro. El `Storage Service` no tiene idea de que hay un OCR downstream. Solo dice: "Archivo subido. H√°ganle lo que quieran."

```go
// Storage Service (productor)
event := events.NewFileUploadedEvent(
    &storage.FileUploadedEventData{
    	FileName: req.FileName,
    	FileKey:  req.FileKey,
    },
)

err := s.producer.Publish(ctx, event)

// OCR Image Service (consumidor 1)
func (c *FileUploadedConsumer) handler(
	ctx context.Context,
	event *events.FileUploadedEvent,
) error {
    // Descarga PDF, genera im√°genes...
}

// Storage Consumer (consumidor 2)
func (c *FileUploadedConsumer) handler(
	ctx context.Context,
	event *events.FileUploadedEvent,
) error {
    // Guarda en DB la metadata del archivo...
}
```

**Escalabilidad gratis:** Si suben 100 PDFs, se pueden levantar m√°s pods en Kubernetes (usando HPA) de `ocr-image`, NATS reparte la carga, y el sistema no suda.

![file-pages](images/file-pages.png)

**La parte dif√≠cil:** Fan-out es poderoso, pero puede convertirse en caos si no documentas qu√© servicios escuchan qu√© eventos. Por eso us√© [EventCatalog](https://www.eventcatalog.dev/) para documentar cada evento, sus productores y consumidores. Sin documentaci√≥n, un a√±o despu√©s nadie recuerda por qu√© el servicio X escucha el evento Y.

---

## Episodio 4: El Fantasma de la Inconsistencia (Outbox Pattern al Rescate)

Aqu√≠ es donde los sistemas distribuidos te patean en la cara.

El `OCR Service` necesita:

1. Guardar en Postgres que la p√°gina X est√° lista.
2. Publicar un evento `FilePageRegisteredEvent` para que el LLM service la procese.

Si hago esto en dos pasos separados, tengo un problema:

- Guardo en DB, falla NATS ‚Üí **Inconsistencia.** La DB dice "listo", pero nadie se enter√≥.
- Publico en NATS, falla la DB ‚Üí **Inconsistencia.** El evento se dispar√≥, pero no hay registro.

### Transactional Outbox Pattern

La soluci√≥n: guardar el evento en una tabla `outbox_events` _dentro de la misma transacci√≥n_ de la base de datos.

```sql
-- Transacci√≥n at√≥mica
BEGIN;
INSERT INTO file_pages (...) VALUES (...);
INSERT INTO outbox_events (event_type, payload) VALUES ('FilePageRegistered', ...);
COMMIT;
```

![outbox-processor](images/outbox-processor.png)

Luego, un proceso background (`OutboxProcessor`) lee la tabla y publica en NATS de forma segura.

### LISTEN/NOTIFY: Latencia Casi Cero

Para que no se sienta lento, uso `LISTEN/NOTIFY` de Postgres. La DB notifica al proceso Go _instant√°neamente_ cuando hay un nuevo evento en la tabla. No polling cada 5 segundos como un animal.

```go
// Listen to outbox notifications
...
	_, err = conn.Exec(ctx, "LISTEN ocr_outbox_channel")
	if err != nil {
		return err
	}

	// Outbox notifications channel
	notifyChan := make(chan struct{})
	go func() {
		for {
			_, err := conn.Conn().WaitForNotification(ctx)
			if err != nil {
				if ctx.Err() != nil {
					return // Context canceled, exit
				}
				continue // Ignore errors and continue listening
			}
			notifyChan <- struct{}{}
		}
	}()

	// Initial backlog
	p.process(ctx)

	ticker := time.NewTicker(30 * time.Second)
	defer ticker.Stop()

	for {
		select {
		case <-notifyChan:
			p.process(ctx)
		case <-ticker.C:
			p.process(ctx)
		case <-ctx.Done():
			return ctx.Err()
		}
	}
...
```

**The hardcore:** El Outbox Pattern es _la_ soluci√≥n correcta para este problema. Pero agrega complejidad. Tienes que gestionar la tabla, limpiar eventos antiguos, y monitorear que el processor no se caiga. Si tu sistema puede vivir con inconsistencia eventual (ej. analytics), quiz√°s no lo necesites. Para OCR, donde cada p√°gina cuenta, no es negociable.

---

## Episodio 5: ORMs son una Mentira (SQLC al Rescate)

Necesitaba ejecutar transacciones SQL complejas. Mi primera opci√≥n fue GORM porque "todos lo usan".

Luego entend√≠ por qu√© los ORMs son la deuda t√©cnica que todos esconden bajo la alfombra: prometen abstraer SQL, pero termin√°s peleando con dos lenguajes a la vez. Cuando algo falla, est√°s debuggeando queries autogeneradas que parecen escritas por alguien que nunca vio un EXPLAIN. Y cuando necesit√°s optimizar, descubres que el ORM te oblig√≥ a cargar 47 objetos relacionados para obtener un solo campo.

El problema no es que los ORMs sean malos per se, el problema es que resuelven un problema que no tienes (escribir SQL b√°sico) creando tres que s√≠ vas a tener (N+1 queries, performance impredecible, y debugging kafkiano).

Us√© [SQLC](https://sqlc.dev/) en su lugar.

### SQLC No es un ORM. Es un Compilador.

Escribes SQL crudo:

```sql
-- name: CreateFilePage :exec
INSERT INTO ocr.file_pages (id, file_id, page_image_key, page_number)
VALUES ($1, $2, $3, $4);

-- name: GetFilePagesByFileID :many
SELECT
    *,
    COUNT(*) OVER() AS total
FROM ocr.file_pages
WHERE file_id = $1
ORDER BY page_number ASC
LIMIT $2 OFFSET $3;
```

SQLC genera c√≥digo Go con type-safety:

```go
// C√≥digo de interfaz generada e implementada por SQLC
type Querier interface {
	CreateFilePage(ctx context.Context, arg CreateFilePageParams) error
	CreateOutboxEvent(ctx context.Context, arg CreateOutboxEventParams) error
	DeleteFilePagesByFileID(ctx context.Context, fileID pgtype.UUID) error
	GetFilePageContentByID(ctx context.Context, id pgtype.UUID) (*string, error)
	GetFilePagesByFileID(ctx context.Context, arg GetFilePagesByFileIDParams) ([]GetFilePagesByFileIDRow, error)
	GetOutboxUnpublishedEvents(ctx context.Context, limit int32) ([]GetOutboxUnpublishedEventsRow, error)
	MarkEventAsPublished(ctx context.Context, eventID pgtype.UUID) error
	UpdateFilePageText(ctx context.Context, arg UpdateFilePageTextParams) error
}
```

**La parte que a algunos no les gusta:** SQLC requiere que realmente conozcas SQL. No te salva de escribir queries malas. Pero si sabes SQL (y deber√≠as), es infinitamente mejor que cualquier ORM que haya usado.

---

## Episodio 6: Migraciones sin Dolor (golang-migrate)

Los schemas de base de datos evolucionan. Gestionar esto con "ejecuta este script en producci√≥n" es una receta para ser despedido.

Us√© [golang-migrate](https://github.com/golang-migrate/migrate). Cada cambio es un par de archivos versionados:

```
migrations/
‚îú‚îÄ‚îÄ embed.go
‚îú‚îÄ‚îÄ ocr
‚îÇ   ‚îú‚îÄ‚îÄ 000001_create_ocr_schema.down.sql
‚îÇ   ‚îú‚îÄ‚îÄ 000001_create_ocr_schema.up.sql
‚îÇ   ‚îú‚îÄ‚îÄ 000002_create_file_pages_table.down.sql
‚îÇ   ‚îú‚îÄ‚îÄ 000002_create_file_pages_table.up.sql
‚îÇ   ‚îú‚îÄ‚îÄ 000003_create_outbox_table.down.sql
‚îÇ   ‚îî‚îÄ‚îÄ 000003_create_outbox_table.up.sql
‚îî‚îÄ‚îÄ storage
    ‚îú‚îÄ‚îÄ 000001_create_storage_schema.down.sql
    ‚îú‚îÄ‚îÄ 000001_create_storage_schema.up.sql
    ‚îú‚îÄ‚îÄ 000002_create_files_table.down.sql
    ‚îú‚îÄ‚îÄ 000002_create_files_table.up.sql
    ‚îú‚îÄ‚îÄ 000003_create_outbox_table.down.sql
    ‚îú‚îÄ‚îÄ 000003_create_outbox_table.up.sql
    ‚îú‚îÄ‚îÄ 000004_create_outbox_notifier.down.sql
    ‚îî‚îÄ‚îÄ 000004_create_outbox_notifier.up.sql
```

Mi aplicaci√≥n ejecuta las migraciones autom√°ticamente al iniciar. Local, staging, y producci√≥n siempre est√°n sincronizados. Si algo sale mal, puedo hacer rollback con un comando.

**Meh:** Esto es b√°sico, no deber√≠a ser notable. Pero he visto suficientes equipos ejecutando scripts SQL manualmente como para saber que _no es obvio para todos_.

---

## Episodio 7: gRPC por Dentro, REST por Fuera (gRPC-Gateway)

Me gusta definir mis apis usando gRPC porque es r√°pido, agn√≥stico del lenguaje y fuertemente tipado. Pero el frontend (React) y clientes externos hablan HTTP/JSON.

Mantener dos APIs separadas es doloroso y propenso a desincronizaci√≥n. Para eso est√° **gRPC-Gateway**.

Agrego anotaciones a mis archivos Protobuf:

```protobuf
service FilesService {
  rpc GetFiles(GetFilesRequest) returns (GetFilesResponse) {
    option (google.api.http) = {get: "/storage/files"};
    option (grpc.gateway.protoc_gen_openapiv2.options.openapiv2_operation) = {
      summary: "Get Files"
      description: "Retrieves a paginated list of files."
      tags: "Files"
    };
  }

  rpc DeleteFiles(DeleteFilesRequest) returns (google.protobuf.Empty) {
    option (google.api.http) = {delete: "/storage/files"};
    option (grpc.gateway.protoc_gen_openapiv2.options.openapiv2_operation) = {
      summary: "Delete Files"
      description: "Deletes multiple files by their keys."
      tags: "Files"
    };
  }
}
```

gRPC-Gateway genera un proxy HTTP que traduce JSON a llamadas gRPC. Una sola definici√≥n, dos interfaces.

**La cruda realidad:** gRPC-Gateway funciona bien para casos simples, pero si tienes necesidades HTTP complejas (file uploads multipart, SSE, websockets), vas a sufrir. Para mi caso de uso, es perfecto. La subida de archivos la maneja S3 directamente, el storage service solo se encarga de generar presigned URLs, y el resto son endpoints simples. En otra iteraci√≥n de este proyecto trabajar√© con streams para mantener al frontend informado del progreso del OCR en near real-time.

---

## Episodio 8: Observabilidad (Porque Todo Va a Fallar)

En un monolito, debuggeas con breakpoints. En microservicios, debuggeas con _trazas distribuidas_.

Integr√© **OpenTelemetry** desde el d√≠a 1. Cada operaci√≥n genera un `Span`, y cuando un mensaje viaja por NATS, el contexto de tracing va con √©l.

El resultado en Jaeger es hermoso: puedo ver exactamente cu√°nto tard√≥ S3, cu√°nto tard√≥ Postgres, cu√°nto tard√≥ el LLM, todo en una timeline continua.

![confirm-upload](images/confirm-upload.png)

**El dolor de cabeza:** Configurar OpenTelemetry es un dolor. La documentaci√≥n es densa, hay 50 formas de hacer la misma cosa, y vas a pasar un d√≠a entero haciendo que funcione. Pero una vez que funciona, debuggear se vuelve _exponencialmente_ m√°s f√°cil.

---

## Conclusiones para Llevar a Casa

¬øVale la pena toda esta complejidad?

**Depende.** üòé

Si est√°s construyendo un CRUD simple con 3 endpoints, no. Usa Rails o Django, despliega en Render, y vete a casa temprano.

Si est√°s construyendo algo que necesita escalar independientemente por partes, que tiene flujos as√≠ncronos largos, o que evoluciona r√°pido con equipos distribuidos... entonces s√≠. EDA y microservicios tienen sentido.

Pero no te enga√±es: **no es gratis**. Pagas con complejidad operativa, curva de aprendizaje, y m√°s cosas que pueden romperse.

Este proyecto, [EDA Workshop](https://github.com/luiscib3r/eda-workshop), es mi intento de mostrar esa realidad. No es un tutorial color de rosa. Es un sistema real, con decisiones reales, y las herramientas que me salvaron de volverme loco.

Si te interesa ver el c√≥digo, romperlo, o copiar patrones para tu propio proyecto, est√° todo en GitHub. Open source, sin paywall, y sin slides de marketing.

**Repositorio:** https://github.com/luiscib3r/eda-workshop

Y la pr√≥xima vez que alguien te venda "Arquitectura Ag√©ntica Revolucionaria powered by IA", preg√∫ntales si implementaron el Outbox Pattern. Si te miran confundidos, sabes que es humo.

---

#GoLang #EventDrivenArchitecture #Microservices #SystemDesign #SoftwareEngineering
